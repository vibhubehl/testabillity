{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSORD_AvgLineCodeExe',\n",
       " 'CSLEX_NumberOfConditionalJumpStatements',\n",
       " 'CSORD_AvgLineCode',\n",
       " 'CSORD_NumberOfDepends',\n",
       " 'CSLEX_NumberOfUniqueIdentifiers',\n",
       " 'CSLEX_NumberOfDots',\n",
       " 'CSORD_CountDeclInstanceMethod',\n",
       " 'CSORD_CountDeclMethodPublic',\n",
       " 'CSORD_NIM',\n",
       " 'CSORD_AvgStmtDecl',\n",
       " 'CSORD_CountDeclClassMethod',\n",
       " 'CSLEX_NumberOfNewStatements',\n",
       " 'CSLEX_NumberOfReturnAndPrintStatements',\n",
       " 'CSORD_NumberOfClassConstructors',\n",
       " 'PK_CountDeclClassMethod']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=r'./dataset/researchDataset/DS07610.csv'\n",
    "df = pd.read_csv(data_path, delimiter=',', index_col=False)\n",
    "df = df.drop('Class', axis=1)\n",
    "df = df.drop('Testability', axis=1)\n",
    "top_15_predictors = list(df.columns)\n",
    "top_15_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PK_CountLineCode</th>\n",
       "      <th>PK_CountLineCodeDecl</th>\n",
       "      <th>PK_CountLineCodeExe</th>\n",
       "      <th>PK_AvgLineCode</th>\n",
       "      <th>PK_AvgLineCodeDecl</th>\n",
       "      <th>PK_AvgLineCodeExe</th>\n",
       "      <th>PK_MaxLineCode</th>\n",
       "      <th>PK_MaxLineCodeDecl</th>\n",
       "      <th>PK_MaxLineCodeExe</th>\n",
       "      <th>PK_MinLineCode</th>\n",
       "      <th>...</th>\n",
       "      <th>CSORD_SumKnots</th>\n",
       "      <th>CSORD_MinKnots</th>\n",
       "      <th>CSORD_MaxKnots</th>\n",
       "      <th>CSORD_AvgKnots</th>\n",
       "      <th>CSORD_SDKnots</th>\n",
       "      <th>CSORD_NumberOfClassConstructors</th>\n",
       "      <th>CSORD_NumberOfDepends</th>\n",
       "      <th>CSORD_NumberOfDependsBy</th>\n",
       "      <th>CSORD_NumberOfMethods</th>\n",
       "      <th>Testability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.28748</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.790031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.611840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PK_CountLineCode  PK_CountLineCodeDecl  PK_CountLineCodeExe  \\\n",
       "0                 0                     0                    0   \n",
       "1                 0                     0                    0   \n",
       "2                 0                     0                    0   \n",
       "3                 0                     0                    0   \n",
       "4                 0                     0                    0   \n",
       "\n",
       "   PK_AvgLineCode  PK_AvgLineCodeDecl  PK_AvgLineCodeExe  PK_MaxLineCode  \\\n",
       "0               0                 0.0                0.0               0   \n",
       "1               0                 0.0                0.0               0   \n",
       "2               0                 0.0                0.0               0   \n",
       "3               0                 0.0                0.0               0   \n",
       "4               0                 0.0                0.0               0   \n",
       "\n",
       "   PK_MaxLineCodeDecl  PK_MaxLineCodeExe  PK_MinLineCode  ...  CSORD_SumKnots  \\\n",
       "0                   0                  0               0  ...               0   \n",
       "1                   0                  0               0  ...               0   \n",
       "2                   0                  0               0  ...               1   \n",
       "3                   0                  0               0  ...               0   \n",
       "4                   0                  0               0  ...               0   \n",
       "\n",
       "   CSORD_MinKnots  CSORD_MaxKnots  CSORD_AvgKnots  CSORD_SDKnots  \\\n",
       "0               0               0        0.000000        0.00000   \n",
       "1               0               0        0.000000        0.00000   \n",
       "2               0               1        0.090909        0.28748   \n",
       "3               0               0        0.000000        0.00000   \n",
       "4               0               0        0.000000        0.00000   \n",
       "\n",
       "   CSORD_NumberOfClassConstructors  CSORD_NumberOfDepends  \\\n",
       "0                                0                      5   \n",
       "1                                0                      3   \n",
       "2                                2                      0   \n",
       "3                                3                      0   \n",
       "4                                2                      1   \n",
       "\n",
       "   CSORD_NumberOfDependsBy  CSORD_NumberOfMethods  Testability  \n",
       "0                        1                      1     0.349560  \n",
       "1                        1                      1     0.312267  \n",
       "2                        6                     11     0.790031  \n",
       "3                        4                      8     0.761905  \n",
       "4                       10                      8     0.611840  \n",
       "\n",
       "[5 rows x 254 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=r'./dataset/researchDataset/DS07012.csv'\n",
    "data = pd.read_csv(data_path, delimiter=',', index_col=False)\n",
    "df = data.drop('Class', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16165, 253)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a pipeline with SelectKBest and LinearRegression as the base estimator\n",
    "feature_selector = SelectKBest(score_func=f_regression)\n",
    "regressor = LinearRegression()\n",
    "pipeline = make_pipeline(feature_selector, regressor)\n",
    "\n",
    "# Define the k values to explore (adjust the range based on your dataset size)\n",
    "param_grid = {'selectkbest__k': range(5, 101, 5)}  # 'selectkbest__k' is the parameter name for k in the pipeline\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the optimal k value and the corresponding pipeline\n",
    "optimal_k = grid_search.best_params_['selectkbest__k']\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Transform the data to the selected features\n",
    "X_new = best_pipeline.named_steps['selectkbest'].transform(X)\n",
    "\n",
    "# Convert the selected features back to a DataFrame\n",
    "selected_feature_indices = best_pipeline.named_steps['selectkbest'].get_support(indices=True)\n",
    "selected_features_df = pd.DataFrame(X_new, columns=[f'Feature_{i+1}' for i in selected_feature_indices])\n",
    "\n",
    "# Concatenate the selected features with the target variable (y) and save to a CSV file\n",
    "selected_features_df['Target'] = y\n",
    "selected_features_df.to_csv('selected_features_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = best_pipeline.named_steps['selectkbest'].get_feature_names_out()\n",
    "selected_k_best = list(feature_names)\n",
    "features_kept = ['Class'] + selected_k_best + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_KBest_CV.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with RFE and LinearRegression as the base estimator\n",
    "estimator = LinearRegression()\n",
    "feature_selector = RFE(estimator=estimator)\n",
    "pipeline = make_pipeline(feature_selector, estimator)\n",
    "\n",
    "# Define the number of features to explore (adjust the range based on your dataset size)\n",
    "param_grid = {'rfe__n_features_to_select': range(5, 101, 5)}  # 'rfe__n_features_to_select' is the parameter name for the number of features to select in the pipeline\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the optimal number of features and the corresponding pipeline\n",
    "optimal_n_features = grid_search.best_params_['rfe__n_features_to_select']\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Transform the data to the selected features\n",
    "X_new = best_pipeline.named_steps['rfe'].transform(X)\n",
    "\n",
    "# Convert the selected features back to a DataFrame\n",
    "selected_features_df = pd.DataFrame(X_new, columns=[f'Feature_{i+1}' for i in range(optimal_n_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = best_pipeline.named_steps['rfe'].get_feature_names_out()\n",
    "selected_k_best = list(feature_names)\n",
    "features_kept = ['Class'] + selected_k_best + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_RFE_CV.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16165, 253)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization (Lasso) with Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.0031622776601683794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the range of alpha values to explore (e.g., from 0.01 to 100)\n",
    "alpha_values = np.logspace(-2.5, 2, num=30)\n",
    "# Create a k-fold cross-validation object (k=5 for example)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Initialize LassoCV with the range of alpha values and use k-fold cross-validation\n",
    "lasso_cv = LassoCV(alphas=alpha_values, cv=kf)\n",
    "# Fit LassoCV to the data\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the optimal alpha value that yielded the best performance during cross-validation\n",
    "optimal_alpha = lasso_cv.alpha_\n",
    "print(\"Optimal alpha:\", optimal_alpha)\n",
    "\n",
    "# Get the selected feature indices based on the optimal alpha\n",
    "selected_feature_indices = np.where(lasso_cv.coef_ != 0)[0]\n",
    "# Get the selected feature names\n",
    "selected_feature_names = X.columns[selected_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=optimal_alpha)  # used optimal choice from LassoCV\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "selected_feature_indices = np.where(lasso.coef_ != 0)[0]\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "len(selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSORD_NumberOfDepends',\n",
       " 'CSLEX_NumberOfUniqueIdentifiers',\n",
       " 'CSLEX_NumberOfDots',\n",
       " 'CSORD_CountDeclInstanceMethod',\n",
       " 'CSORD_NIM',\n",
       " 'CSORD_CountDeclClassMethod',\n",
       " 'CSLEX_NumberOfNewStatements',\n",
       " 'CSORD_NumberOfClassConstructors',\n",
       " 'PK_CountDeclClassMethod']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_predictors = [x for x in top_15_predictors if x in selected_feature_names]\n",
    "common_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LassoCV with an optimized alpha ~0.03 produced a subset with 45 features selected. 9 of the top 15 predictors are in this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lasso_cv = list(selected_feature_names)\n",
    "features_kept = ['Class'] + selected_lasso_cv + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_LassoCV_k45.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1-based feature selection with Lasso and Cross-Validation.\n",
    "LassoCV runs Lasso/L1 regularization, a univariate selection method, with cross-validation to select the most important features, tuning the regularization strength alpha.\n",
    "\n",
    "LassoCV is useful when you have many features and suspect that many of them are irrelevant or redundant. Automatically selects a subset of the most relevant features by setting the coefficients of less important features to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE) with linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create a base model for RFE (SVR)\n",
    "model = SVR(kernel='linear')\n",
    "\n",
    "# Create RFE object with the model and the desired number of features to select\n",
    "n_features_to_select = 45  # Specify the number of top features to select\n",
    "rfe = RFE(model, n_features_to_select=45)\n",
    "\n",
    "# Fit RFE to the data\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the mask of selected features (True for selected features, False for others)\n",
    "selected_feature_mask = rfe.support_\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X.columns[selected_feature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe = list(selected_feature_names)\n",
    "features_kept = ['Class'] + selected_rfe + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_RFE_k45.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE) with rbf SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16165, 45)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Save the column names for later use\n",
    "column_names = X.columns\n",
    "\n",
    "# Create a PCA object\n",
    "n_components = 45  # Specify the number of top components to retain\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the data using PCA\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Get the indices of the features with the highest loadings in each component\n",
    "top_feature_indices = np.abs(pca.components_).argmax(axis=1)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = column_names[top_feature_indices]\n",
    "\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pca = list(selected_feature_names)\n",
    "features_kept = ['Class'] + selected_pca + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_PCA_k45.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_threshold = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "X_new = var_threshold.fit_transform(X)\n",
    "feature_names = var_threshold.get_feature_names_out()\n",
    "feature_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features all have significant variance, a threshold of 0.2 only eliminated 5 features, 0.1 variance eliminated 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSORD_AvgLineCodeExe', 'CSORD_AvgLineCode', 'CSORD_AvgStmtDecl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "k_best = SelectKBest(f_regression, k=45)\n",
    "\n",
    "X_new = k_best.fit_transform(X, y)\n",
    "feature_names = k_best.get_feature_names_out()\n",
    "select_k_best_predictors = list(feature_names)\n",
    "common_predictors = [x for x in top_15_predictors if x in select_k_best_predictors]\n",
    "common_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest is a univariate feature selection method, evaluates each feature independently without considering the relationship between features.\n",
    "Used f_regression to rank the features, it then selects the top K features with the highest scores\n",
    "\n",
    "Standard regression SelectKBest with k=15 found 3 of the top 15 predictors found by paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_k_best = list(feature_names)\n",
    "features_kept = ['Class'] + selected_k_best + ['Testability']\n",
    "feature_selected_data = data.filter(features_kept)\n",
    "\n",
    "new_data_path=r'./dataset/newDataset/DS_K45.csv'\n",
    "feature_selected_data.to_csv(new_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=estimator,\n",
    "    step=5,\n",
    "    min_features_to_select=15,\n",
    "    cv=3\n",
    ")\n",
    "rfecv.fit(X_new, y)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV Takes extremely long to run even with smaller dataset with 40 features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
