{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionGridSearch:\n",
    "    def __init__(self, df_path):\n",
    "        # Read input data from given path\n",
    "        df = pd.read_csv(df_path, delimiter=',', index_col=False)\n",
    "\n",
    "        # Split training and testing data 70:30\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df.iloc[:, 1:-1],\n",
    "            df.iloc[:, -1],\n",
    "            test_size=0.3,\n",
    "            random_state=1,\n",
    "        )\n",
    "\n",
    "        # Scale numerical values with same method as paper being reproduced\n",
    "        scaler = QuantileTransformer(n_quantiles=1000, random_state=1)\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        # Store X any y values in regression object instance\n",
    "        self.X_train = scaler.transform(X_train)\n",
    "        self.X_test = scaler.transform(X_test)\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def grid_search(self, regressor, parameters, print_results=False):\n",
    "        # Measures used for each model\n",
    "        scoring = ['neg_root_mean_squared_error', ]\n",
    "\n",
    "        # Cross Validator used for Grid Search\n",
    "        cv = ShuffleSplit(\n",
    "            test_size=0.3, random_state=1\n",
    "        )\n",
    "\n",
    "        # Find the best model using grid-search with above cross-validation\n",
    "        clf = GridSearchCV(\n",
    "            regressor,\n",
    "            param_grid=parameters,\n",
    "            scoring=scoring,\n",
    "            cv=cv,\n",
    "            refit='neg_root_mean_squared_error'\n",
    "        )\n",
    "        clf.fit(X=self.X_train, y=self.y_train)\n",
    "\n",
    "        # Print grid search results\n",
    "        if print_results:\n",
    "            print('Grid Search Results:')\n",
    "            print(' (*) Best parameters set found on development set:', clf.best_params_)\n",
    "            print(' (*) Best classifier score on development set:', clf.best_score_)\n",
    "            print(' (*) Best classifier score on test set:', clf.score(self.X_test, self.y_test))\n",
    "\n",
    "        # Return resulting estimator\n",
    "        return(clf.best_estimator_)\n",
    "\n",
    "    def evaluate_model(self, model, print_results=False):\n",
    "        # Use given model to predict y values\n",
    "        y_true, y_pred = self.y_test, model.predict(self.X_test)\n",
    "\n",
    "        # Extract stats\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        mdae = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Print model metrics\n",
    "        if print_results:\n",
    "            print('Evaluating regressor:')\n",
    "            print(' (*) R^2 Score:', r2)\n",
    "            print(' (*) Mean Absolute Error:', mae)\n",
    "            print(' (*) Mean Squared Error:', mse)\n",
    "            print(' (*) Root Mean Squared Error:', rmse)\n",
    "            print(' (*) Median Absolute Error:', mdae)\n",
    "\n",
    "        # Return stats in dict\n",
    "        stats = {\n",
    "            'r2': r2,\n",
    "            'mae': mae,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mdae': mdae\n",
    "        }\n",
    "        return(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(regressor=None, parameters=None, ds_number=6):\n",
    "    # Use one of the 5 datasets from study to initialize regression model search\n",
    "    if ds_number == 1:\n",
    "        df_path=r'./dataset/researchDataset/DS07012.csv' # DS1\n",
    "    elif ds_number == 2:\n",
    "        df_path=r'./dataset/researchDataset/DS07310.csv' # DS2\n",
    "    elif ds_number == 3:\n",
    "        df_path=r'./dataset/researchDataset/DS07410.csv' # DS3\n",
    "    elif ds_number == 4:\n",
    "        df_path=r'./dataset/researchDataset/DS07510.csv' # DS4\n",
    "    elif ds_number == 5:\n",
    "        df_path=r'./dataset/researchDataset/DS07610.csv' # DS5\n",
    "    \n",
    "    # Run grid search on provided regression model and params\n",
    "    reg_gs = RegressionGridSearch(df_path)\n",
    "    best_model = reg_gs.grid_search(regressor, parameters)\n",
    "    model_stats = reg_gs.evaluate_model(best_model)\n",
    "    return(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regressor_stats(regressor, parameters, datasets=[1, 2, 3, 4, 5]):\n",
    "    for ds_number in datasets:\n",
    "        best_estimator_stats = run_grid_search(regressor, parameters, ds_number=ds_number)\n",
    "        # For visualization and comparison of models we can update this to send stats somewhere other than print\n",
    "        print(f'Best estimator stats on dataset {ds_number}:')\n",
    "        print(best_estimator_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator stats on dataset 3:\n",
      "{'r2': 0.4926700922053632, 'mae': 0.15367447949520668, 'mse': 0.04453985954009794, 'rmse': 0.21104468612144192, 'mdae': 0.11083928193309642}\n",
      "Best estimator stats on dataset 4:\n",
      "{'r2': 0.514867457762517, 'mae': 0.14847369070327543, 'mse': 0.042591093009905434, 'rmse': 0.206376096023511, 'mdae': 0.10507204405227522}\n",
      "Best estimator stats on dataset 5:\n",
      "{'r2': 0.5211559260151406, 'mae': 0.15040792895336572, 'mse': 0.0420390114385434, 'rmse': 0.20503417139233987, 'mdae': 0.11350829702566342}\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=1)\n",
    "parameters = {\n",
    "    'max_depth': range(3, 50, 5),\n",
    "    'min_samples_split': range(2, 30, 2)\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters, [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(random_state=1)\n",
    "parameters = {\n",
    "    'n_estimators': range(100, 200, 100),\n",
    "    'max_depth': range(10, 50, 10)\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = GradientBoostingRegressor(n_estimators=400, learning_rate=0.05, random_state=1)\n",
    "parameters = {\n",
    "    'max_depth': range(10, 50, 10),\n",
    "    'min_samples_split': range(2, 30, 3)\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor(max_iter=400, learning_rate=0.05, random_state=1)\n",
    "parameters = {\n",
    "    'max_depth': range(10, 50, 10),\n",
    "    'min_samples_leaf': range(5, 50, 10)\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = linear_model.SGDRegressor(early_stopping=True, n_iter_no_change=5, random_state=1)\n",
    "parameters = {\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'max_iter': range(50, 1000, 50),\n",
    "    'learning_rate': ['invscaling', 'optimal', 'constant', 'adaptive'],\n",
    "    'eta0': [0.1, 0.01],\n",
    "    'average': [32, ]\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = MLPRegressor(random_state=1)\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(256, 100), (512, 256, 100), ],\n",
    "    'activation': ['tanh', ],\n",
    "    'solver': ['adam', ],\n",
    "    'max_iter': range(50, 200, 50)\n",
    "}\n",
    "compute_regressor_stats(regressor, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
